{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing to Learn Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarah_functions import*\n",
    "\n",
    "# Basic data science packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# for cleaning\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# For analyses\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# For visualization\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The seaborn library makes plots look nicer\n",
    "sns.set(style=\"darkgrid\", palette = 'rocket', font_scale = 2,rc={\"lines.linewidth\":2.5})\n",
    "sns.set_context('talk')\n",
    "\n",
    "# Round decimals when displaying DataFrames\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Set matplotlib preferences\n",
    "font = {'family' : 'Bitstream Vera Sans',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 13}\n",
    "\n",
    "# set standard fig size\n",
    "figure = {'figsize' : (10,8)}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('figure', **figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/sarahamiraslani/Desktop/Black_holes+coding.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>VVIQ16</th>\n",
       "      <th>Q126</th>\n",
       "      <th>SC0</th>\n",
       "      <th>Test Order</th>\n",
       "      <th>total retention (jiawen)</th>\n",
       "      <th>total retention (sarah)</th>\n",
       "      <th>lowest retention</th>\n",
       "      <th>total transfer (Jiawen)</th>\n",
       "      <th>total transfer (Sarah)</th>\n",
       "      <th>Lowest Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43563.62</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>0</td>\n",
       "      <td>132.239.182.138</td>\n",
       "      <td>100</td>\n",
       "      <td>2245</td>\n",
       "      <td>1</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>R_1mDlxbJ3HlQzADi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>AB</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43563.62</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>0</td>\n",
       "      <td>132.239.182.140</td>\n",
       "      <td>100</td>\n",
       "      <td>2271</td>\n",
       "      <td>1</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>R_3HqzxCZyweOsA12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   StartDate   EndDate  Status        IPAddress  Progress  \\\n",
       "0   43563.62  43563.65       0  132.239.182.138       100   \n",
       "1   43563.62  43563.65       0  132.239.182.140       100   \n",
       "\n",
       "   Duration (in seconds)  Finished  RecordedDate         ResponseId  \\\n",
       "0                   2245         1      43563.65  R_1mDlxbJ3HlQzADi   \n",
       "1                   2271         1      43563.65  R_3HqzxCZyweOsA12   \n",
       "\n",
       "   RecipientLastName       ...         VVIQ16  Q126  SC0  Test Order  \\\n",
       "0                NaN       ...            1.0   NaN  100          AB   \n",
       "1                NaN       ...            3.0   NaN   69          AB   \n",
       "\n",
       "   total retention (jiawen) total retention (sarah) lowest retention  \\\n",
       "0                       4.0                     4.0              4.0   \n",
       "1                       2.0                     2.0              2.0   \n",
       "\n",
       "   total transfer (Jiawen) total transfer (Sarah)  Lowest Transfer  \n",
       "0                      3.0                    4.0              3.0  \n",
       "1                      3.0                    3.0              3.0  \n",
       "\n",
       "[2 rows x 186 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n",
    "# df_bh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_df = df[['R1','R2','R3','R4','T1','T2','T3','T4']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>R_all</th>\n",
       "      <th>T_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A black hole is an indefinite space. It is nam...</td>\n",
       "      <td>Two stars collapse</td>\n",
       "      <td>The black is made up of a center (a ball of ne...</td>\n",
       "      <td>singularity is the enlargment of a center beca...</td>\n",
       "      <td>As a rocket approaches the center of a black h...</td>\n",
       "      <td>It did not exceed the mass of both stars</td>\n",
       "      <td>Me, since time is less near black holes</td>\n",
       "      <td>6 solar masses is greater than the 3 neede for...</td>\n",
       "      <td>A black hole is an indefinite space. It is nam...</td>\n",
       "      <td>As a rocket approaches the center of a black h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a black hole is a hole in space that is black ...</td>\n",
       "      <td>A black hole can be formed by the collision of...</td>\n",
       "      <td>angular momemtum</td>\n",
       "      <td>space and time are similar in that time seems ...</td>\n",
       "      <td>if it gets close enough to the black hole, it ...</td>\n",
       "      <td>the explosion may not have been as large as it...</td>\n",
       "      <td>I have, since them moving closer makes time go...</td>\n",
       "      <td>it would produce a black hole</td>\n",
       "      <td>a black hole is a hole in space that is black ...</td>\n",
       "      <td>if it gets close enough to the black hole, it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  R1  \\\n",
       "0  A black hole is an indefinite space. It is nam...   \n",
       "1  a black hole is a hole in space that is black ...   \n",
       "\n",
       "                                                  R2  \\\n",
       "0                                 Two stars collapse   \n",
       "1  A black hole can be formed by the collision of...   \n",
       "\n",
       "                                                  R3  \\\n",
       "0  The black is made up of a center (a ball of ne...   \n",
       "1                                   angular momemtum   \n",
       "\n",
       "                                                  R4  \\\n",
       "0  singularity is the enlargment of a center beca...   \n",
       "1  space and time are similar in that time seems ...   \n",
       "\n",
       "                                                  T1  \\\n",
       "0  As a rocket approaches the center of a black h...   \n",
       "1  if it gets close enough to the black hole, it ...   \n",
       "\n",
       "                                                  T2  \\\n",
       "0           It did not exceed the mass of both stars   \n",
       "1  the explosion may not have been as large as it...   \n",
       "\n",
       "                                                  T3  \\\n",
       "0            Me, since time is less near black holes   \n",
       "1  I have, since them moving closer makes time go...   \n",
       "\n",
       "                                                  T4  \\\n",
       "0  6 solar masses is greater than the 3 neede for...   \n",
       "1                      it would produce a black hole   \n",
       "\n",
       "                                               R_all  \\\n",
       "0  A black hole is an indefinite space. It is nam...   \n",
       "1  a black hole is a hole in space that is black ...   \n",
       "\n",
       "                                               T_all  \n",
       "0  As a rocket approaches the center of a black h...  \n",
       "1  if it gets close enough to the black hole, it ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds_df['R_all']=wrds_df['R1']+wrds_df['R2']+wrds_df['R3']+wrds_df['R4']\n",
    "wrds_df['T_all']=wrds_df['T1']+wrds_df['T2']+wrds_df['T3']+wrds_df['T4']\n",
    "wrds_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ret_unique_wrds']= wrds_df['R_all'].apply(unique_word_calc)\n",
    "df['trans_unique_wrds']= wrds_df['T_all'].apply(unique_word_calc)\n",
    "\n",
    "df['ret_total_wrds']= wrds_df['R_all'].apply(total_word_calc)\n",
    "df['trans_total_wrds']= wrds_df['T_all'].apply(total_word_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>total retention (jiawen)</th>\n",
       "      <th>total retention (sarah)</th>\n",
       "      <th>lowest retention</th>\n",
       "      <th>total transfer (Jiawen)</th>\n",
       "      <th>total transfer (Sarah)</th>\n",
       "      <th>Lowest Transfer</th>\n",
       "      <th>ret_unique_wrds</th>\n",
       "      <th>trans_unique_wrds</th>\n",
       "      <th>ret_total_wrds</th>\n",
       "      <th>trans_total_wrds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43563.62</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>0</td>\n",
       "      <td>132.239.182.138</td>\n",
       "      <td>100</td>\n",
       "      <td>2245</td>\n",
       "      <td>1</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>R_1mDlxbJ3HlQzADi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43563.62</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>0</td>\n",
       "      <td>132.239.182.140</td>\n",
       "      <td>100</td>\n",
       "      <td>2271</td>\n",
       "      <td>1</td>\n",
       "      <td>43563.65</td>\n",
       "      <td>R_3HqzxCZyweOsA12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   StartDate   EndDate  Status        IPAddress  Progress  \\\n",
       "0   43563.62  43563.65       0  132.239.182.138       100   \n",
       "1   43563.62  43563.65       0  132.239.182.140       100   \n",
       "\n",
       "   Duration (in seconds)  Finished  RecordedDate         ResponseId  \\\n",
       "0                   2245         1      43563.65  R_1mDlxbJ3HlQzADi   \n",
       "1                   2271         1      43563.65  R_3HqzxCZyweOsA12   \n",
       "\n",
       "   RecipientLastName        ...         total retention (jiawen)  \\\n",
       "0                NaN        ...                              4.0   \n",
       "1                NaN        ...                              2.0   \n",
       "\n",
       "   total retention (sarah)  lowest retention  total transfer (Jiawen)  \\\n",
       "0                      4.0               4.0                      3.0   \n",
       "1                      2.0               2.0                      3.0   \n",
       "\n",
       "   total transfer (Sarah) Lowest Transfer ret_unique_wrds  trans_unique_wrds  \\\n",
       "0                     4.0             3.0              48                 33   \n",
       "1                     3.0             3.0              29                 33   \n",
       "\n",
       "  ret_total_wrds  trans_total_wrds  \n",
       "0             89                44  \n",
       "1             45                43  \n",
       "\n",
       "[2 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualtrics exports lots of extra columns that we wont use in analyses\n",
    "\n",
    "# dropping extra columns\n",
    "useless_cols = [ 'StartDate','EndDate', 'Status','IPAddress','ResponseId',\n",
    "                'Progress','Finished','RecipientLastName', 'RecipientEmail', \n",
    "                'ExternalReference','LocationLatitude', 'LocationLongitude', \n",
    "                'DistributionChannel','Time on demographics_First Click',\n",
    "                'Time on demographics_Last Click','Time on demographics_Page Submit', \n",
    "                'Time on demographics_Click Count', 'Time on PK_First Click',\n",
    "                'Time on PK_Last Click','Time on PK_Page Submit','Time on PK_Click Count',\n",
    "                'Time, Test A, Part 1_First Click','Time, Test A, Part 1_Click Count',\n",
    "                \"Time, Test A, Part 1_Last Click\" , \"Time, Test A, P2_First Click\",\n",
    "                \"Time, Test A, P2_Last Click\",\"Time, Test A, P2_Click Count\", \n",
    "                \"Time, Test A, P3_First Click\",\"Time, Test A, P3_Last Click\",\n",
    "                \"Time, Test A, P3_Click Count\", 'Time, Test B, P1_First Click',\n",
    "                'Time, Test B, P1_Last Click','Time, Test B, P1_Click Count', \n",
    "                'Time TestB, P2_First Click','Time TestB, P2_Last Click',\n",
    "                \"Time TestB, P2_Click Count\",'Time, TestB, P3_First Click',\n",
    "                'Time, TestB, P3_Last Click','Time, TestB, P3_Click Count',\n",
    "                'Q162_First Click','Q162_Last Click','Time reading_First Click',\n",
    "                'Time reading_Last Click','Time reading_Click Count', 'Q113_First Click',\n",
    "                'Q113_Last Click','Q113_Click Count','Q114_First Click','Q114_Last Click',\n",
    "                'Q115_First Click','Q115_Last Click','Q115_Click Count','Q114_Click Count',\n",
    "                'Q115_First Click','Q115_Last Click','Q115_Click Count', 'Time_First Click',\n",
    "                'Time_Last Click','Time_Click Count','SC0', 'UserLanguage','RecipientFirstName',\n",
    "                'Q162_Click Count','SC0','R1 confidence','R2 confidence','R3 confidence',\n",
    "                'R4 confidence', 'T1 confidence','T2 confidence','T3 confidence','T4 confidence']\n",
    "\n",
    "df.drop(useless_cols, axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the names of the columns\n",
    "\n",
    "# Coursse_history\n",
    "df['Course_history'] = df['Course history']\n",
    "\n",
    "# Time spent reading the complete instructions\n",
    "df['complete_inst_time_sec'] = df['Q162_Page Submit']\n",
    "df['copy_inst_time_sec'] = df['Q113_Page Submit']\n",
    "df['study_inst_time_sec'] = df['Q115_Page Submit']\n",
    "df['draw_inst_time_sec'] = df['Q114_Page Submit']\n",
    "\n",
    "# Perceived difficulty of visualization activity\n",
    "df['complete_difficulty'] = df['Q60']\n",
    "df['copy_difficulty'] = df['Q57']\n",
    "df['study_difficulty'] = df['Q62']\n",
    "df['drawing_difficulty'] = df['Draw-rating1']\n",
    "\n",
    "# Visualization activity enjoyment\n",
    "df['complete_enjoyment'] = df['Q61']\n",
    "df['copy_enjoyment'] = df['Q58']\n",
    "df['study_enjoyment'] = df['Q63']\n",
    "df['drawing_enjoyment']=df['Draw - rating 2']\n",
    "\n",
    "# Have you seen the photograph of the black hole? \n",
    "df['seen BH pic?'] = df['Q126']\n",
    "\n",
    "# Time spent in seconds filling out cognitive load questionnaire\n",
    "df['time CL questionnaire'] = df['Time_Page Submit']\n",
    "\n",
    "df['time spent reading'] = df['Time reading_Page Submit']\n",
    "\n",
    "# self reported prior knowledge specific to black holes\n",
    "df['BH confidence before manipulation(self-reported)'] = df['confidence - BH']\n",
    "df['BH confidence post manipulation(self-reported)']= df['Confidnece']+ df['Q106']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['retention_j']=df_bh['Total retention Jiawen']\n",
    "df_bh['retention_s']=df_bh['total retention sarah']\n",
    "df_bh['lowest_retention']=df_bh['lowest retention']\n",
    "df_bh['transfer_j']=df_bh['total transfer (Jiawen)']\n",
    "df_bh['transfer_s']=df_bh['total transfer (Sarah)']\n",
    "df_bh['lowest_transfer']=df_bh['Lowest transfer']\n",
    "\n",
    "to_drop = ['Total retention Jiawen', 'total retention sarah', 'lowest retention',\n",
    "           'total transfer (Jiawen)', 'total transfer (Sarah)', 'Lowest transfer']\n",
    "\n",
    "df_bh.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename attention check questions\n",
    "df_bh['attn1'] = df_bh['attn']\n",
    "df_bh['attn2'] = df_bh['attn.1']\n",
    "df_bh['attn3'] = df_bh['CL_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh.loc[df_bh.attn1== '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh.loc[df_bh.attn2== '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh.loc[df_bh.attn3!= '7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove those who fail at least one of three attention check questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh = df_bh[df_bh.attn1!= '0']\n",
    "df_bh = df_bh[df_bh.attn2!= '0']\n",
    "df_bh = df_bh[df_bh.attn3== '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that participants were removed\n",
    "assert len(df_bh.loc[df_bh['attn1']=='0']) == 0\n",
    "assert len(df_bh.loc[df_bh['attn2']=='0']) == 0\n",
    "assert len(df_bh.loc[df_bh['attn3']!= '7']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove participants who did not follow illustration instructions\n",
    "df_bh.drop([4],axis=0,inplace=True) #b4\n",
    "df_bh.drop([38],axis=0,inplace=True)# subID O6\n",
    "df_bh.drop([148],axis=0,inplace=True)# subID O43\n",
    "df_bh.drop([149],axis=0,inplace=True)# subID O41\n",
    "\n",
    "df_bh.drop([22],axis =0,inplace=True)# subID G3\n",
    "df_bh.drop([65],axis=0,inplace=True)# subID G19\n",
    "df_bh.drop([140],axis=0,inplace=True)# subID G39\n",
    "df_bh.drop([219],axis=0,inplace=True)# subID G60\n",
    "\n",
    "df_bh.drop([19],axis=0,inplace=True)# subID B14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with more than 5 missing values. \n",
    "df_bh.dropna(axis=0,thresh = 5,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type of 'Condition' and 'Gender' to allow for string manipulations\n",
    "df_bh['Condition'] = df_bh['Condition'].astype(str)\n",
    "df_bh['Gender'] = df_bh['Gender'].astype(str)\n",
    "\n",
    "# Change entries in column 'day_of_week' to represent the day of the week in words\n",
    "df_bh['Condition'] = df_bh['Condition'].replace('1','study')\n",
    "df_bh['Condition'] = df_bh['Condition'].replace('2','copy')\n",
    "df_bh['Condition'] = df_bh['Condition'].replace('3','complete')\n",
    "df_bh['Condition'] = df_bh['Condition'].replace('4','draw')\n",
    "\n",
    "# Change entries in column 'Gender' to represent reported gender in words\n",
    "df_bh['Gender'] = df_bh['Gender'].replace('1','male')\n",
    "df_bh['Gender'] = df_bh['Gender'].replace('2','female')\n",
    "df_bh['Gender'] = df_bh['Gender'].replace('3','non-binary')\n",
    "\n",
    "# Making everything lowercase\n",
    "df_bh['Major'] = df_bh.Major.str.lower()\n",
    "df_bh['Course history'] = df_bh.Course_history.str.lower()\n",
    "df_bh['SubID'] = df_bh.SubID.str.lower()\n",
    "\n",
    "# Remove extra white spaces\n",
    "df_bh['Major'] = df_bh.Major.str.strip()\n",
    "df_bh['Course_history'] = df_bh.Course_history.str.strip \n",
    "df_bh['SubID'] = df_bh.SubID.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_vars = ['VVIQ1', 'VVIQ2','VVIQ3','VVIQ4','VVIQ5','VVIQ6','VVIQ7',\n",
    "                  'VVIQ8','VVIQ9', 'VVIQ10', 'VVIQ11','VVIQ12','VVIQ13',\n",
    "                  'VVIQ14','VV1Q15','VVIQ16', 'A2', 'A3', 'A4', 'A6','A7',\n",
    "                  'A8','A9','A10','A11','A12','A14','A15','B2','B3','B4',\n",
    "                  'B6','B7','B8','B9','B10','B11','B12','B14','B15', \n",
    "                  'Time, Test A, Part 1_Page Submit',\n",
    "                  'Time, Test A, P2_Page Submit','Time, Test A, P3_Page Submit',\n",
    "                  'Time, Test B, P1_Page Submit','Time TestB, P2_Page Submit',\n",
    "                  'Time, TestB, P3_Page Submit','CL_1','CL_2','CL_3','CL_4',\n",
    "                  'CL_5','CL_7','CL_8','CL_9','CL_10','CL_11','PK_1',\n",
    "                  'Confidence PK_1','PK_2','Confidence PK_2']\n",
    "\n",
    "df_cont = df_bh[continous_vars].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new VVIQ total score column \n",
    "df_bh['VVIQ Total Score']=df_cont['VVIQ1'] + df_cont['VVIQ2']+ df_cont['VVIQ3']+ \\\n",
    "    df_cont['VVIQ4']+ df_cont['VVIQ5']+ df_cont['VVIQ6'] + df_cont['VVIQ7']+ \\\n",
    "    df_cont['VVIQ8'] + df_cont['VVIQ9'] + df_cont['VVIQ10'] + df_cont['VVIQ11']+\\\n",
    "    df_cont['VVIQ12'] + df_cont['VVIQ13'] + df_cont['VVIQ14'] + df_cont['VV1Q15'] +\\\n",
    "    df_cont['VVIQ16']\n",
    "\n",
    "# Create Test A, Test B multiple choice columns\n",
    "# Note A1 abd B1 do not exist -- I mislabelled the qualtrics survey so that the first Q is called A2/B2\n",
    "df_bh['Test A Total Score'] = df_cont['A2']+ df_cont['A3']+ df_cont['A4']+ df_cont['A6']+ \\\n",
    "    df_cont['A7']+ df_cont['A8']+ df_cont['A9']+ df_cont['A10']+ df_cont['A11']+ \\\n",
    "    df_cont['A12']+ df_cont['A14']+ df_cont['A15']\n",
    "\n",
    "df_bh['Test B Total Score'] = df_cont['B2']+ df_cont['B3']+ df_cont['B4']+ df_cont['B6']+\\\n",
    "    df_cont['B7']+ df_cont['B8']+ df_cont['B9']+ df_cont['B10']+ df_cont['B11']+ \\\n",
    "    df_cont['B12']+ df_cont['B14']+ df_cont['B15']\n",
    "\n",
    "# Create a new column for time spent on Test A and Test B\n",
    "df_bh['Time_spent_TestA'] = df_cont['Time, Test A, Part 1_Page Submit']+ \\\n",
    "    df_cont['Time, Test A, P2_Page Submit']+ df_cont['Time, Test A, P3_Page Submit']\n",
    "\n",
    "df_bh['Time_spent_TestB'] = df_cont['Time, Test B, P1_Page Submit']+ \\\n",
    "    df_cont['Time TestB, P2_Page Submit']+ df_cont['Time, TestB, P3_Page Submit']\n",
    "\n",
    "# Create cognitive load and subcomponent columns\n",
    "# Total cognitive load\n",
    "# CL6 was the attention check Q\n",
    "df_bh['Total CL'] = df_cont['CL_1']+ df_cont['CL_2']+ df_cont['CL_3']+ df_cont['CL_4']+\\\n",
    "    df_cont['CL_5']+ df_cont['CL_7']+ df_cont['CL_8']+ df_cont['CL_9']+ \\\n",
    "    df_cont['CL_10']+df_cont['CL_11']\n",
    "\n",
    "# Total intrinsic load\n",
    "df_bh['Total IL'] = df_cont['CL_1']+ df_cont['CL_2']+ df_cont['CL_3']\n",
    "\n",
    "# Total extraneous load\n",
    "df_bh['Total EL'] = df_cont['CL_4']+ df_cont['CL_5']+ df_cont['CL_7']\n",
    "\n",
    "# Total germane load\n",
    "df_bh['Total GL'] =df_cont['CL_8']+ df_cont['CL_9']+ df_cont['CL_10']+ df_cont['CL_11']\n",
    "\n",
    "# Compute participants'total prior knowledge score (self-reported)\n",
    "#PK_1 refers to physics and PK_2 to astro\n",
    "df_bh['Cummulative PK']= (df_cont['PK_1']* df_cont['Confidence PK_1'])+ \\\n",
    "    (df_cont['PK_2']*df_cont['Confidence PK_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have cummulative scores these columns are no longer useful\n",
    "df_bh.drop(continous_vars,axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two empty columns to the dataframe\n",
    "df_bh['Pretest_score']=np.nan\n",
    "df_bh['Posttest_score']=np.nan\n",
    "\n",
    "# Fill the empty columns with the appropriate pre and post test\n",
    "for col,row in df_bh.iterrows():\n",
    "        \n",
    "    if df_bh.loc[col, 'Test Order'] == 'BA': \n",
    "        \n",
    "        df_bh.loc[col,'Pretest_score'] = df_bh.loc[col,'Test B Total Score']\n",
    "        df_bh.loc[col,'Posttest_score']= df_bh.loc[col,'Test A Total Score']\n",
    "\n",
    "    elif df_bh.loc[col,'Test Order'] == 'AB':\n",
    "\n",
    "        df_bh.loc[col,'Pretest_score']= df_bh.loc[col,'Test A Total Score']\n",
    "        df_bh.loc[col,'Posttest_score']= df_bh.loc[col,'Test B Total Score']\n",
    "\n",
    "\n",
    "#Create a multiple choice gain\n",
    "df_bh['MC Gain']= df_bh['Posttest_score'] - df_bh['Pretest_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median split\n",
    "# Divide participants into high and low prior knowledge groups based on  median prior knowledge\n",
    "\n",
    "median = df_bh.loc[:,\"Cummulative PK\"].median()\n",
    "df_bh['PK Split']=np.nan\n",
    "    \n",
    "for col,row in df_bh.iterrows(): \n",
    "\n",
    "    if df_bh.loc[col,\"Cummulative PK\"] < median: \n",
    "        \n",
    "        df_bh.loc[col,'PK Split'] = 'Low'\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        df_bh.loc[col,'PK Split'] ='High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['complete_inst_time_sec'] = df_bh['complete_inst_time_sec'].fillna('')\n",
    "df_bh['copy_inst_time_sec'] = df_bh['copy_inst_time_sec'].fillna('')\n",
    "df_bh['study_inst_time_sec'] = df_bh['study_inst_time_sec'].fillna('')\n",
    "df_bh['draw_inst_time_sec'] = df_bh['draw_inst_time_sec'].fillna('')\n",
    "\n",
    "lst =[]\n",
    "\n",
    "for index,row in df_bh.iterrows():\n",
    "    lst.append(row.complete_inst_time_sec+row.copy_inst_time_sec+row.study_inst_time_sec+row.draw_inst_time_sec)\n",
    "\n",
    "df_bh['time_read_inst']=lst \n",
    "\n",
    "to_drop = ['draw_inst_time_sec','study_inst_time_sec','copy_inst_time_sec','complete_inst_time_sec']\n",
    "df_bh.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['complete_difficulty'] = df_bh['complete_difficulty'].fillna(0)\n",
    "df_bh['copy_difficulty'] = df_bh['copy_difficulty'].fillna(0)\n",
    "df_bh['study_difficulty']=df_bh['study_difficulty'].fillna(0)\n",
    "df_bh['draw_difficulty']=df_bh['drawing_difficulty'].fillna(0)\n",
    "\n",
    "df_bh['complete_difficulty'] = df_bh['complete_difficulty'].astype(int)\n",
    "df_bh['copy_difficulty'] = df_bh['copy_difficulty'].astype(int)\n",
    "df_bh['study_difficulty']= df_bh['study_difficulty'].astype(int)\n",
    "df_bh['draw_difficulty']= df_bh['draw_difficulty'].astype(int)\n",
    "lst =[]\n",
    "\n",
    "for index,row in df_bh.iterrows():\n",
    "    lst.append(row.complete_difficulty+row.copy_difficulty+row.study_difficulty+row.draw_difficulty)\n",
    "\n",
    "df_bh['cond_difficulty']=lst\n",
    "\n",
    "    \n",
    "to_drop = ['complete_difficulty','copy_difficulty','study_difficulty','draw_difficulty']\n",
    "df_bh.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['complete_enjoyment']= df_bh['complete_enjoyment'].fillna(0)\n",
    "df_bh['copy_enjoyment']= df_bh['copy_enjoyment'].fillna(0)\n",
    "df_bh['study_enjoyment']= df_bh['study_enjoyment'].fillna(0)       \n",
    "df_bh['draw_enjoyment']= df_bh['drawing_enjoyment'].fillna(0) \n",
    "\n",
    "df_bh['complete_enjoyment']=df_bh['complete_enjoyment'].astype(int)\n",
    "df_bh['copy_enjoyment']= df_bh['copy_enjoyment'].astype(int)\n",
    "df_bh['study_enjoyment']=df_bh['study_enjoyment'].astype(int)\n",
    "df_bh['draw_enjoyment']=df_bh['draw_enjoyment'].astype(int)\n",
    "\n",
    "lst =[]\n",
    "\n",
    "for index,row in df_bh.iterrows():\n",
    "    lst.append(row.complete_enjoyment+row.copy_enjoyment+row.study_enjoyment+row.draw_enjoyment)\n",
    "\n",
    "df_bh['cond_enjoyment']=lst\n",
    "\n",
    "to_drop = ['complete_enjoyment','copy_enjoyment','study_enjoyment','draw_enjoyment']\n",
    "df_bh.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting date and time for RecordedDate\n",
    "date_time = df_bh['RecordedDate'].str.split(' ', n=1, expand=True)\n",
    "df_bh.drop(['RecordedDate'], axis=1,inplace = True)\n",
    "df_bh['date'] = date_time[0]\n",
    "df_bh['time'] = date_time[1]\n",
    "# convert the 'Date' column to datetime format \n",
    "# df_bh['date']= pd.to_datetime(df_bh['date']) \n",
    "# df_bh['time']= pd.to_datetime(df_bh['time']) \n",
    "\n",
    "# Changing datatype and changing units sec -> min\n",
    "df_bh['Duration(s)'] = df_bh['Duration (in seconds)'].astype(int)\n",
    "df_bh['Duration(min)'] = df_bh['Duration(s)'].multiply(1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['date'] = df_bh['date'].astype(str)\n",
    "df_bh['day_of_week']=df_bh['date'].apply(day_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['time']=df_bh['time'].apply(time_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bh['Time_spent_TestA_min'] = df_bh['Time_spent_TestA'].multiply(1/60)\n",
    "\n",
    "df_bh['Time_spent_TestB_min'] = df_bh['Time_spent_TestB'].multiply(1/60)\n",
    "\n",
    "df_bh['time spent reading'] = df_bh['time spent reading'].astype(float)\n",
    "df_bh['time spent reading_min'] = df_bh['time spent reading'].multiply(1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping columns that are no longer needed\n",
    "to_drop = ['Duration (in seconds)','Q60',\n",
    "           'Q61','Q57','Q63','Q58','Q62','Q106','Confidnece',\n",
    "           'Q106','Q126','Q114_Page Submit','Q115_Page Submit',\n",
    "           'Q162_Page Submit','Q113_Page Submit','R1','R2','R3',\n",
    "           'R4','T1','T2','T3','T4','Last thought - BH',\n",
    "           'First learned - BH','Course history','confidence - BH',\n",
    "           'Confidnece','Q106','attn1', 'attn2','attn3','Duration(s)', \n",
    "           'Q128_First Click','Q128_Last Click','Q128_Page Submit',\n",
    "           'Q129_First Click','Q129_Last Click','Q129_Page Submit',\n",
    "           'Q129_Click Count','Q128_Click Count','Time_Page Submit',\n",
    "           'Draw-rating1','Draw - rating 2','Time reading_Page Submit',\n",
    "           'Duration (in seconds)']\n",
    "\n",
    "df_bh.drop(to_drop, axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder \n",
    "small_df_bh = df_bh[['SubID','date','time','day_of_week','week','Condition','Age', 'Gender','Cummulative PK',\n",
    "            'PK Split','Test Order','Test A Total Score','Time_spent_TestA_min',\n",
    "            'Test B Total Score','Time_spent_TestB_min','Pretest_score','Posttest_score',\n",
    "            'MC Gain','time spent reading_min','lowest_retention','lowest_transfer',\n",
    "            'cond_difficulty','cond_enjoyment','Total CL','Total IL','Total EL',\n",
    "            'Total GL','VVIQ Total Score','retention_total_words','retention_unique_words',\n",
    "            'transfer_total_words','transfer_unique_words']]\n",
    "\n",
    "small_df_bh.columns = ['SubID','date','time','day_of_week','week','condition','age', 'gender','prior_knowledge','pk_Split',\n",
    "                    'test_order','test_A','time_testA','test_B','time_testB','pretest_score',\n",
    "                    'posttest_score','mc_gain','time_reading','retention','transfer','cond_difficulty',\n",
    "                    'cond_enjoyment','CL','IL','EL','GL','vviq','retention_total_words','retention_unique_words',\n",
    "                    'transfer_total_words','transfer_unique_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh=pd.DataFrame(small_df_bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh.to_excel(\"/Users/sarahamiraslani/Documents/GitHub/Drawing to Learn Science/BH/cleaned_df_small.xlsx\")\n",
    "df_bh.to_excel(\"/Users/sarahamiraslani/Documents/GitHub/Drawing to Learn Science/BH/cleaned_df_large.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh = pd.read_excel('/Users/sarahamiraslani/Desktop/cleaned_df_small_FIXED_May6_2020.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = small_df_bh.groupby(['condition']).mean()\n",
    "\n",
    "avg_IL = filtered['IL']\n",
    "avg_EL = filtered['EL']\n",
    "avg_GL = filtered['GL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.25\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(avg_IL))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "#Groupings\n",
    "plt.bar(r1, avg_GL, width=barWidth, edgecolor='white', label='Germane Load')\n",
    "plt.bar(r2, avg_IL, width=barWidth, edgecolor='white', label='Intrinsic Load')\n",
    "plt.bar(r3, avg_EL, width=barWidth, edgecolor='white', label='Extraneous Load')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Self-reported Load')\n",
    "plt.title('Cognitive Load Profiles by Condition');\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(avg_IL))], ['study','copy','complete','draw'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "sns.barplot(x='day_of_week',y='mc_gain',data=small_df_bh,order=['monday','tuesday','wednesday',\n",
    "                                                                             'thursday','friday'])\n",
    "\n",
    "plt.title('MC Performance by Weekday');\n",
    "plt.xlabel('Day of the week that data was collected');\n",
    "plt.ylabel('Multiple Choice Gain');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['retention']=small_df_bh['retention'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "sns.barplot(x='day_of_week',y='retention',data=small_df_bh,\n",
    "            order=['monday','tuesday','wednesday','thursday','friday'])\n",
    "\n",
    "plt.title('Retention Performance by Weekday');\n",
    "plt.xlabel('Day of the week that data was collected');\n",
    "plt.ylabel('Retention Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_vviq = ols('retention ~ C(day_of_week)',data=small_df_bh).fit()\n",
    "anova_vviq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['transfer']=small_df_bh['transfer'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "sns.barplot(x='day_of_week',y='transfer',data=small_df_bh,\n",
    "            order=['monday','tuesday','wednesday','thursday','friday'])\n",
    "\n",
    "plt.title('Transfer Performance by Weekday');\n",
    "plt.xlabel('Day of the week that data was collected');\n",
    "plt.ylabel('Transfer Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,20))\n",
    "sns.barplot(x='week',y='retention',data=small_df_bh);\n",
    "\n",
    "plt.title('Retention Performance by Weekday');\n",
    "plt.xlabel('Week of S19 Quarter');\n",
    "plt.ylabel('Retention Test Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_week = ols('retention ~ C(week)',data=small_df_bh).fit()\n",
    "anova_vviq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['retention']=small_df_bh['retention'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "sns.barplot(x='time',y='retention',data=small_df_bh, \n",
    "           order=['11:00 AM','12:00 PM','3:00 PM','4:00 PM','5:00 PM','6:00 PM','7:00 PM'])\n",
    "plt.xlabel('Time that session started');\n",
    "plt.ylabel('Performance on Retention Test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['prior_knowledge'],bins=25,range =(1,50),density = True)\n",
    "\n",
    "plt.title('Self-reported Prior Knowledge') \n",
    "plt.xlabel('Prior Knowledge')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "pk_min=round(small_df_bh['prior_knowledge'].min(),3)\n",
    "pk_max = round(small_df_bh['prior_knowledge'].max(),3)\n",
    "pk_mean = round(small_df_bh['prior_knowledge'].mean(),3)\n",
    "pk_std = round(small_df_bh['prior_knowledge'].std(),3)\n",
    "pk_med = round(small_df_bh['prior_knowledge'].median(),3)\n",
    "\n",
    "print('Self-reported Prior Knowledge \\n\\nMean: ' +str(pk_mean),'\\tStandard dev: '+ str(pk_std))\n",
    "      \n",
    "print('\\nMin: ' + str(pk_min),'\\tMedian: '+ str(pk_med),'\\tMax: '+str(pk_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='prior_knowledge',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Self-reported Prior Knowledge by Condition') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('Prior Knowledge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: `time spent reading` the passage provides insight into the extent that participants engaged with the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['time_reading'],bins=25,range =(10,40),density = True)\n",
    "\n",
    "plt.title('Time Reading Black Holes Passage') \n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "read_min=round(small_df_bh['time_reading'].min(),3)\n",
    "read_max = round(small_df_bh['time_reading'].max(),3)\n",
    "read_mean = round(small_df_bh['time_reading'].mean(),3)\n",
    "read_std = round(small_df_bh['time_reading'].std(),3)\n",
    "read_med = round(small_df_bh['time_reading'].median(),3)\n",
    "\n",
    "print('Time reading summary \\n\\nMean: ' +str(read_mean),'\\tStandard dev: '+ str(read_std))\n",
    "      \n",
    "print('\\nMin: ' + str(read_min),'\\tMedian: '+ str(read_med),'\\tMax: '+str(read_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='time_reading',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Time Spent Reading Black Holes Passage by Condition') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('time (min)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-test\n",
    "\n",
    "plt.hist(small_df_bh['pretest_score'],bins=10, label = 'pretest score')\n",
    "\n",
    "plt.title('Histogram of Pre-test score') \n",
    "plt.xlabel('score (out of 15)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "pretest_min=round(small_df_bh['pretest_score'].min(),3)\n",
    "pretest_max = round(small_df_bh['pretest_score'].max(),3)\n",
    "pretest_mean = round(small_df_bh['pretest_score'].mean(),3)\n",
    "pretest_std = round(small_df_bh['pretest_score'].std(),3)\n",
    "pretest_med = round(small_df_bh['pretest_score'].median(),3)\n",
    "\n",
    "\n",
    "print('Multiple choice pretest Score Summary \\n\\nMean: ' +str(pretest_mean),'\\tStandard dev: '+str(pretest_std))\n",
    "print('\\nMin: ' +str(pretest_min), '\\tMedian: '+str(pretest_med),'\\tMax: '+str(pretest_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='pretest_score',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Performance on the MC Pre-Test by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (out of 12)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: visualize `post test` score as a formality. We care less about this variable as we are interested in the points gained between the pre and post test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-test\n",
    "\n",
    "plt.hist(small_df_bh['posttest_score'],bins=10, label = 'posttest_score')\n",
    "\n",
    "plt.title('Histogram of Post-test Score') \n",
    "plt.xlabel('Score (out of 15)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "posttest_min=round(small_df_bh['posttest_score'].min(),3)\n",
    "posttest_max = round(small_df_bh['posttest_score'].max(),3)\n",
    "posttest_mean = round(small_df_bh['posttest_score'].mean(),3)\n",
    "posttest_std = round(small_df_bh['posttest_score'].std(),3)\n",
    "posttest_med = round(small_df_bh['posttest_score'].median(),3)\n",
    "\n",
    "\n",
    "print('Multiple choice posttest Score \\n\\nMean: ' +str(posttest_mean),'\\tStandard dev: '+str(posttest_std))\n",
    "print('\\nMin: ' +str(posttest_min), '\\tMedian: '+str(posttest_med),'\\tMax: '+str(posttest_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='posttest_score',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Performance on the MC Post-Test by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (out of 12)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: visualize `multiple choice` gain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC-Gain\n",
    "\n",
    "\n",
    "plt.hist(small_df_bh['mc_gain'],bins=10, label = 'mc_gain')\n",
    "\n",
    "plt.title('Multiple Choice Gain') \n",
    "plt.xlabel('mc_gain')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "mc_gain_min=round(small_df_bh['mc_gain'].min(),3)\n",
    "mc_gain_max = round(small_df_bh['mc_gain'].max(),3)\n",
    "mc_gain_mean = round(small_df_bh['mc_gain'].mean(),3)\n",
    "mc_gain_std = round(small_df_bh['mc_gain'].std(),3)\n",
    "mc_gain_med = round(small_df_bh['mc_gain'].median(),3)\n",
    "\n",
    "\n",
    "print('Multiple choice gain \\n\\nMean: ' +str(mc_gain_mean),'\\tStandard dev: '+str(mc_gain_std))\n",
    "print('\\nMin: ' +str(mc_gain_min), '\\tMedian: '+str(mc_gain_med),'\\tMax: '+str(mc_gain_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='mc_gain',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Black Holes: Multiple Choice Gain by Condition',fontweight='bold') \n",
    "plt.xlabel('Condition',fontweight='bold')\n",
    "plt.ylabel('Score (max is 12)',fontweight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: visualize performance on Test A and Test B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = plt.hist(small_df_bh['test_A'],bins=10)\n",
    "\n",
    "plt.title('test_A') \n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f3 = plt.gcf()\n",
    "\n",
    "tA_min=round(small_df_bh['test_A'].min(),3)\n",
    "tA_max = round(small_df_bh['test_A'].max(),3)\n",
    "tA_mean = round(small_df_bh['test_A'].mean(),3)\n",
    "tA_std = round(small_df_bh['test_A'].std(),3)\n",
    "tA_med = round(small_df_bh['test_A'].median(),3)\n",
    "\n",
    "print('Test A\\n\\nMean: ' +str(tA_mean),'\\tStandard dev: '+str(tA_std))\n",
    "print('\\nMin: '+str(tA_min),'\\tMedian: '+str(tA_med) + '\\tMax: '+str(tA_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='test_A',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Test A by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 15)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_b = plt.hist(df_bh['Test B Total Score'],bins=10)\n",
    "\n",
    "plt.title('Test B Total Score') \n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f4 = plt.gcf()\n",
    "\n",
    "tB_min=round(small_df_bh['test_B'].min(),3)\n",
    "tB_max = round(small_df_bh['test_B'].max(),3)\n",
    "tB_mean = round(small_df_bh['test_B'].mean(),3)\n",
    "tB_std = round(small_df_bh['test_B'].std(),3)\n",
    "tB_med = round(small_df_bh['test_B'].median(),3)\n",
    "\n",
    "print('Test B\\n\\nMean: ' +str(tB_mean),'\\tStandard dev: '+str(tB_std))\n",
    "print('\\nMin: '+str(tB_min),'\\tMedian: ' +str(tB_med),'\\tMax: '+str(tB_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='test_B',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Test B by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 15)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of VVIQ\n",
    "vviq = plt.hist(small_df_bh['vviq'],bins=10,label = 'Test A')\n",
    "\n",
    "plt.title('Visual Imagery Ability') \n",
    "plt.xlabel('Score on the VVIQ')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "vviq_min=round(small_df_bh['vviq'].min(),3)\n",
    "vviq_max = round(small_df_bh['vviq'].max(),3)\n",
    "vviq_mean = round(small_df_bh['vviq'].mean(),3)\n",
    "vviq_std = round(small_df_bh['vviq'].std(),3)\n",
    "vviq_med = round(small_df_bh['vviq'].median(),3)\n",
    "\n",
    "\n",
    "print('vviq \\n\\nMean: ' +str(vviq_mean),'\\tStandard dev: '+str(vviq_std))\n",
    "print('\\nMin: ' +str(vviq_min), '\\tMedian: '+str(vviq_med),'\\tMax: '+str(vviq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='vviq',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('VVIQ by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 15)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['IL','EL','GL']\n",
    "\n",
    "pd.scatter_matrix(small_df_bh[cols],figsize=(40,30),diagonal= 'hist')\n",
    "\n",
    "f5 = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram total cognitive load\n",
    "tot_cl = plt.hist(small_df_bh['CL'],bins=15, label = 'Total CL')\n",
    "\n",
    "plt.title('Total Self-Reported Cognitive Load') \n",
    "plt.xlabel('Cognitive load (max is 100)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "cl_min=round(small_df_bh['CL'].min(),3)\n",
    "cl_max = round(small_df_bh['CL'].max(),3)\n",
    "cl_mean = round(small_df_bh['CL'].mean(),3)\n",
    "cl_std = round(small_df_bh['CL'].std(),3)\n",
    "cl_med = round(small_df_bh['CL'].median(),3)\n",
    "\n",
    "print('Cognitive Load \\n\\nMean: ' +str(cl_mean),'\\tStandard dev: '+str(cl_std))\n",
    "print('\\nMin: ' +str(cl_min), '\\tMedian: '+str(cl_med),'\\tMax: '+str(cl_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='CL',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Cognitive load by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 100)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='retention',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['IL'],bins=10, label = 'IL')\n",
    "\n",
    "\n",
    "plt.title('Total Self-Reported Intrinsic Load') \n",
    "plt.xlabel('Intrinsic load')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "il_min=round(small_df_bh['IL'].min(),3)\n",
    "il_max = round(small_df_bh['IL'].max(),3)\n",
    "il_mean = round(small_df_bh['IL'].mean(),3)\n",
    "il_std = round(small_df_bh['IL'].std(),3)\n",
    "il_med = round(small_df_bh['IL'].median(),3)\n",
    "\n",
    "\n",
    "print('Intrinsic Load \\n\\nMean: ' +str(il_mean),'\\tStandard dev: '+str(il_std))\n",
    "print('\\nMin: ' +str(il_min), '\\tMedian: '+str(il_med),'\\tMax: '+str(il_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='IL',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Intrinsic load by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 30)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['GL'],bins=10,label = 'GL')\n",
    "\n",
    "\n",
    "plt.title('Total Self-Reported Germane Load') \n",
    "plt.xlabel('Germane load')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "gl_min=round(small_df_bh['GL'].min(),3)\n",
    "gl_max = round(small_df_bh['GL'].max(),3)\n",
    "gl_mean = round(small_df_bh['GL'].mean(),3)\n",
    "gl_std = round(small_df_bh['GL'].std(),3)\n",
    "gl_med = round(small_df_bh['GL'].median(),3)\n",
    "\n",
    "\n",
    "print('Germane Load \\n\\nMean: ' +str(gl_mean),'\\tStandard dev: '+str(gl_std))\n",
    "print('\\nMin: ' +str(gl_min), '\\tMedian: '+str(gl_med),'\\tMax: '+str(gl_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='GL',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Germane load by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 40)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['EL'],bins=10,label = 'EL')\n",
    "\n",
    "plt.title('Total Self-Reported Extraneous Load') \n",
    "plt.xlabel('Extraneous load')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "el_min=round(small_df_bh['EL'].min(),3)\n",
    "el_max = round(small_df_bh['EL'].max(),3)\n",
    "el_mean = round(small_df_bh['EL'].mean(),3)\n",
    "el_std = round(small_df_bh['EL'].std(),3)\n",
    "el_med = round(small_df_bh['EL'].median(),3)\n",
    "\n",
    "\n",
    "print('Extraneous Load \\n\\nMean: ' +str(el_mean),'\\tStandard dev: '+str(el_std))\n",
    "print('\\nMin: ' +str(el_min), '\\tMedian: '+str(el_med),'\\tMax: '+str(el_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='EL',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Extraneous load by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 30)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['cond_enjoyment'],bins=5,label = 'cond_enjoyment')\n",
    "\n",
    "plt.title('Total Self-Reported Condition Enjoyment') \n",
    "plt.xlabel('Extraneous load')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "ce_min=round(small_df_bh['cond_enjoyment'].min(),3)\n",
    "ce_max = round(small_df_bh['cond_enjoyment'].max(),3)\n",
    "ce_mean = round(small_df_bh['cond_enjoyment'].mean(),3)\n",
    "ce_std = round(small_df_bh['cond_enjoyment'].std(),3)\n",
    "ce_med = round(small_df_bh['cond_enjoyment'].median(),3)\n",
    "\n",
    "\n",
    "print('Condition Enjoyment \\n\\nMean: ' +str(ce_mean),'\\tstandard dev: '+str(ce_std))\n",
    "print('\\nMin: ' +str(ce_min), '\\tMedian: '+str(ce_med),'\\tMax: '+str(ce_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='cond_enjoyment',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Visualization Activity Enjoyment by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 5)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlaying histograms of Test A and Test B performance\n",
    "test_a = plt.hist(df_bh['Test A Total Score'],bins=10, alpha=0.5, label = 'Test A')\n",
    "test_b = plt.hist(df_bh['Test B Total Score'],bins=10, alpha=0.25, label = 'Test B')\n",
    "\n",
    "# customize plot\n",
    "plt.title('MC Test Version Performance') \n",
    "plt.legend(loc= 'upper right')\n",
    "plt.xlabel('Score on open multiple choice Test')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['retention']=small_df_bh['retention'].astype(int)\n",
    "\n",
    "plt.hist(small_df_bh['retention'],bins=14,label = 'retention')\n",
    "\n",
    "plt.title('Total Open Response Retention Score') \n",
    "plt.xlabel('Score (max is 22)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "or_min=round(small_df_bh['retention'].min(),3)\n",
    "or_max = round(small_df_bh['retention'].max(),3)\n",
    "or_mean = round(small_df_bh['retention'].mean(),3)\n",
    "or_std = round(small_df_bh['retention'].std(),3)\n",
    "or_med = round(small_df_bh['retention'].median(),3)\n",
    "\n",
    "\n",
    "print('Retention \\n\\nMean: ' +str(or_mean),'\\tstandard dev: '+str(or_std))\n",
    "print('\\nMin: ' +str(or_min), '\\tMedian: '+str(or_med),'\\tMax: '+str(or_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='retention',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Black holes: Open Response Retention Test by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 22)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['transfer']=small_df_bh['transfer'].astype(int)\n",
    "\n",
    "plt.hist(small_df_bh['transfer'],bins=7,label = 'transfer')\n",
    "\n",
    "plt.title('Total Open Response Transfer Test Score') \n",
    "plt.xlabel('Score (max is 16)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "ot_min=round(small_df_bh['transfer'].min(),3)\n",
    "ot_max = round(small_df_bh['transfer'].max(),3)\n",
    "ot_mean = round(small_df_bh['transfer'].mean(),3)\n",
    "ot_std = round(small_df_bh['transfer'].std(),3)\n",
    "ot_med = round(small_df_bh['transfer'].median(),3)\n",
    "\n",
    "\n",
    "print('Transfer \\n\\nMean: ' +str(ot_mean),'\\tstandard dev: '+str(ot_std))\n",
    "print('\\nMin: ' +str(ot_min), '\\tMedian: '+str(ot_med),'\\tMax: '+str(ot_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='transfer',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Black Holes: Open Response Transfer Test by Condition') \n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Score (max is 16)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['retention_unique_words'],bins=25,range =(10,150),density = True)\n",
    "\n",
    "plt.title('Number of Unique Words by Condition') \n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "unique_min=round(small_df_bh['retention_unique_words'].min(),3)\n",
    "unique_max = round(small_df_bh['retention_unique_words'].max(),3)\n",
    "unique_mean = round(small_df_bh['retention_unique_words'].mean(),3)\n",
    "unique_std = round(small_df_bh['retention_unique_words'].std(),3)\n",
    "unique_med = round(small_df_bh['retention_unique_words'].median(),3)\n",
    "\n",
    "print('Unique Words summary \\n\\nMean: ' +str(unique_mean),'\\tStandard dev: '+ str(unique_std))\n",
    "      \n",
    "print('\\nMin: ' + str(unique_min),'\\tMedian: '+ str(unique_med),'\\tMax: '+str(unique_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['transfer_unique_words'],bins=25,range =(10,150),density = True)\n",
    "\n",
    "plt.title('Number of Unique Words by Condition') \n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "unique_min=round(small_df_bh['transfer_unique_words'].min(),3)\n",
    "unique_max = round(small_df_bh['transfer_unique_words'].max(),3)\n",
    "unique_mean = round(small_df_bh['transfer_unique_words'].mean(),3)\n",
    "unique_std = round(small_df_bh['transfer_unique_words'].std(),3)\n",
    "unique_med = round(small_df_bh['transfer_unique_words'].median(),3)\n",
    "\n",
    "print('Unique Words summary \\n\\nMean: ' +str(unique_mean),'\\tStandard dev: '+ str(unique_std))\n",
    "      \n",
    "print('\\nMin: ' + str(unique_min),'\\tMedian: '+ str(unique_med),'\\tMax: '+str(unique_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(y='retention_unique_words',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Number of Unique Words by Condition - Retention') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('Words')\n",
    "\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='transfer_unique_words',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Number of Unique Words by Condition - Transfer') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('Words')\n",
    "\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['retention_total_words'],bins=25,range =(20,600),density = True)\n",
    "\n",
    "plt.title('Number of Total Words') \n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "total_min=round(small_df_bh['retention_total_words'].min(),3)\n",
    "total_max = round(small_df_bh['retention_total_words'].max(),3)\n",
    "total_mean = round(small_df_bh['retention_total_words'].mean(),3)\n",
    "total_std = round(small_df_bh['retention_total_words'].std(),3)\n",
    "total_med = round(small_df_bh['retention_total_words'].median(),3)\n",
    "\n",
    "print('Total Words summary \\n\\nMean: ' +str(total_mean),'\\tStandard dev: '+ str(total_std))\n",
    "      \n",
    "print('\\nMin: ' + str(total_min),'\\tMedian: '+ str(total_med),'\\tMax: '+str(total_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(small_df_bh['transfer_total_words'],bins=25,range =(20,600),density = True)\n",
    "\n",
    "plt.title('Number of Total Words') \n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "f2 = plt.gcf() # get current figure \n",
    "\n",
    "total_min=round(small_df_bh['transfer_total_words'].min(),3)\n",
    "total_max = round(small_df_bh['transfer_total_words'].max(),3)\n",
    "total_mean = round(small_df_bh['transfer_total_words'].mean(),3)\n",
    "total_std = round(small_df_bh['transfer_total_words'].std(),3)\n",
    "total_med = round(small_df_bh['transfer_total_words'].median(),3)\n",
    "\n",
    "print('Total Words summary \\n\\nMean: ' +str(total_mean),'\\tStandard dev: '+ str(total_std))\n",
    "      \n",
    "print('\\nMin: ' + str(total_min),'\\tMedian: '+ str(total_med),'\\tMax: '+str(total_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(y='retention_total_words',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Number of Total Words by Condition') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('Words')\n",
    "\n",
    "plt.ylim(0, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(y='transfer_total_words',x='condition',data=small_df_bh,order=['study','copy','complete','draw'])\n",
    "\n",
    "plt.title('Number of Total Words by Condition') \n",
    "plt.xlabel('condition')\n",
    "plt.ylabel('Words')\n",
    "\n",
    "plt.ylim(0, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='prior_knowledge',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Prior Knowledge and Retention - BH') \n",
    "plt.xlabel('Prior Knowledge (self-reported)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='prior_knowledge',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Prior Knowledge and Transfer - BH') \n",
    "plt.xlabel('Prior Knowledge (self-reported)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='time_reading',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Time Reading and Retention') \n",
    "plt.xlabel('Prior Knowledge (self-reported)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='time_reading',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Time Reading and Transfer') \n",
    "plt.xlabel('Prior Knowledge (self-reported)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='CL',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Cognitive Load and Transfer') \n",
    "plt.xlabel('Cognitive Load (100 max)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='CL',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Cognitive Load and Retention') \n",
    "plt.xlabel('Cognitive Load (100 max)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='IL',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Intrinsic Load and Transfer') \n",
    "plt.xlabel('Intrinsic Load (30 max)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='IL',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Intrinsic Load and Retention') \n",
    "plt.xlabel('Intrinsic Load (30 max)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='EL',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Extraneous Load and Transfer') \n",
    "plt.xlabel('Extraneous Load (30 max)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='EL',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Extraneous Load and Retention') \n",
    "plt.xlabel('Extraneous Load (30 max)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='GL',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Germane Load and Transfer') \n",
    "plt.xlabel('Germane Load (40 max)')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='GL',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Germane Load and Retention') \n",
    "plt.xlabel('Germane Load (40 max)')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='retention_total_words',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Total Words and Retention') \n",
    "plt.xlabel('Total Words Used')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='transfer_total_words',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Total Words and Transfer') \n",
    "plt.xlabel('Total Words Used')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='transfer_unique_words',y='transfer',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Unique Words and Transfer') \n",
    "plt.xlabel('Unique Words Used')\n",
    "plt.ylabel('Transfer test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='retention_unique_words',y='retention',data=small_df_bh)\n",
    "\n",
    "plt.title('Regression of Unique Words and Retention') \n",
    "plt.xlabel('Unique Words Used')\n",
    "plt.ylabel('Retention test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='time_reading',y='retention',\n",
    "           col='condition',col_wrap=2,data=small_df_bh,\n",
    "           truncate=True,line_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='time_reading',y='transfer',\n",
    "           col='condition',col_wrap=2,data=small_df_bh,\n",
    "           truncate=True,line_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_df_bh['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['age']=small_df_bh['age'].apply(remove_punctuation)\n",
    "small_df_bh['age']=small_df_bh['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['age'].mean()\n",
    "small_df_bh['age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate descriptive stats\n",
    "desc = small_df_bh.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for differences across groups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.levene.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.levene(small_df_bh['prior_knowledge'][small_df_bh['condition']=='study'], \n",
    "                small_df_bh['prior_knowledge'][small_df_bh['condition']=='copy'],\n",
    "                small_df_bh['prior_knowledge'][small_df_bh['condition']=='complete'], \n",
    "                small_df_bh['prior_knowledge'][small_df_bh['condition']=='draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_pk = ols('prior_knowledge ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_pk.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.shapiro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.shapiro(anova_pk.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.levene(small_df_bh['vviq'][small_df_bh['condition']=='study'], \n",
    "                small_df_bh['vviq'][small_df_bh['condition']=='copy'],\n",
    "                small_df_bh['vviq'][small_df_bh['condition']=='complete'], \n",
    "                small_df_bh['vviq'][small_df_bh['condition']=='draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_vviq = ols('vviq ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_vviq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['vviq'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['vviq'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['vviq'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.shapiro(anova_vviq.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.levene(small_df_bh['pretest_score'][small_df_bh['condition']=='study'], \n",
    "                small_df_bh['pretest_score'][small_df_bh['condition']=='copy'],\n",
    "                small_df_bh['pretest_score'][small_df_bh['condition']=='complete'], \n",
    "                small_df_bh['pretest_score'][small_df_bh['condition']=='draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_pretest = ols('pretest_score ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_pretest.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['pretest_score'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['pretest_score'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.shapiro(anova_pk.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Planned analyses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_mc = ols('mc_gain ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_mc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['mc_gain'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['mc_gain'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_retention = ols('retention ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_retention.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['retention'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['retention'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['retention'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['retention'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['retention'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['retention'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['retention'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['retention'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_transfer = ols('transfer ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['transfer'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['transfer'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['transfer'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exploratory analyses**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_enjoyment = ols('cond_enjoyment ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_enjoyment.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_time_read = ols('time_reading ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_time_read.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_cl = ols('CL ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_cl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['CL'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['CL'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['CL'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['CL'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['CL'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['CL'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['CL'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['CL'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_il = ols('IL ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_il.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['IL'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['IL'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['IL'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['IL'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['IL'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['IL'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['IL'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['IL'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_el = ols('EL ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_el.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['EL'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['EL'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['EL'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['EL'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['EL'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['EL'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['EL'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['EL'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_gl = ols('GL ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_gl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_bh['GL'][small_df_bh['condition']=='study'].mean()\n",
    "small_df_bh['GL'][small_df_bh['condition']=='study'].std()\n",
    "\n",
    "small_df_bh['GL'][small_df_bh['condition']=='copy'].mean()\n",
    "small_df_bh['GL'][small_df_bh['condition']=='copy'].std()\n",
    "\n",
    "small_df_bh['GL'][small_df_bh['condition']=='complete'].mean()\n",
    "small_df_bh['GL'][small_df_bh['condition']=='complete'].std()\n",
    "             \n",
    "small_df_bh['GL'][small_df_bh['condition']=='draw'].mean()\n",
    "small_df_bh['GL'][small_df_bh['condition']=='draw'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_pre_mc = ols('pretest_score ~ C(condition)',\n",
    "                      data=small_df_bh).fit()\n",
    "anova_pre_mc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_post_mc = ols('posttest_score ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_post_mc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_unique_w = ols('retention_unique_words ~ C(condition)',data=small_df_bh).fit()\n",
    "anova_unique_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anova_total_w = ols('retention_total_words ~ C(condition)',\n",
    "                      data=small_df_bh).fit()\n",
    "anova_total_w.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
